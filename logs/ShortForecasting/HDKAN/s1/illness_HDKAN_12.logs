Args in experiment:
Namespace(random_seed=2025, enable_visual=False, save_model=False, percent=100, patch_len=3, degree1=5, degree2=5, is_training=1, model_id='illness_12_12', model='HDKAN', data='custom', root_path='D:\\work\\datasets\\all_datasets\\short-term', data_path='national_illness.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=12, label_len=0, pred_len=12, use_revin=1, enc_in=7, dec_in=7, c_out=7, d_model=256, dropout=0.0, alpha=0.35, embed='timeF', num_workers=0, itr=1, train_epochs=20, batch_size=8, patience=5, learning_rate=0.0004, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', inverse=False)
Use GPU: cuda:0
>>>>>>>start training : illness_12_12_HDKAN_custom_ftM_bz8_sl12_pl12_lr0.0004_dm256_d15_d25_patl3_dr0.0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 653
val 86
test 182
Epoch: 1 cost time: 0.6708426475524902
Epoch: 1, Steps: 81 | Train Loss: 1.1712261 Vali Loss: 1.3068992 Test Loss: 4.5112495
Validation loss decreased (inf --> 1.306899).  Saving model ...
Updating learning rate to 0.0004
Epoch: 2 cost time: 0.49933433532714844
Epoch: 2, Steps: 81 | Train Loss: 0.9105419 Vali Loss: 0.9216479 Test Loss: 2.6672196
Validation loss decreased (1.306899 --> 0.921648).  Saving model ...
Updating learning rate to 0.0004
Epoch: 3 cost time: 0.49335432052612305
Epoch: 3, Steps: 81 | Train Loss: 0.8515935 Vali Loss: 0.9473843 Test Loss: 2.6660151
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0004
Epoch: 4 cost time: 0.4973411560058594
Epoch: 4, Steps: 81 | Train Loss: 0.8188735 Vali Loss: 0.9044531 Test Loss: 2.5045860
Validation loss decreased (0.921648 --> 0.904453).  Saving model ...
Updating learning rate to 0.00032
Epoch: 5 cost time: 0.4959108829498291
Epoch: 5, Steps: 81 | Train Loss: 0.7913030 Vali Loss: 0.8616936 Test Loss: 2.3683276
Validation loss decreased (0.904453 --> 0.861694).  Saving model ...
Updating learning rate to 0.00025600000000000004
Epoch: 6 cost time: 0.5003306865692139
Epoch: 6, Steps: 81 | Train Loss: 0.7636522 Vali Loss: 0.8938873 Test Loss: 2.3693376
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00020480000000000004
Epoch: 7 cost time: 0.5242512226104736
Epoch: 7, Steps: 81 | Train Loss: 0.7399457 Vali Loss: 0.8232659 Test Loss: 1.9722745
Validation loss decreased (0.861694 --> 0.823266).  Saving model ...
Updating learning rate to 0.00016384000000000003
Epoch: 8 cost time: 0.4953474998474121
Epoch: 8, Steps: 81 | Train Loss: 0.7144474 Vali Loss: 0.7754589 Test Loss: 1.8885940
Validation loss decreased (0.823266 --> 0.775459).  Saving model ...
Updating learning rate to 0.00013107200000000004
Epoch: 9 cost time: 0.5178461074829102
Epoch: 9, Steps: 81 | Train Loss: 0.6892261 Vali Loss: 0.7395348 Test Loss: 1.8273278
Validation loss decreased (0.775459 --> 0.739535).  Saving model ...
Updating learning rate to 0.00010485760000000004
Epoch: 10 cost time: 0.5033209323883057
Epoch: 10, Steps: 81 | Train Loss: 0.6690713 Vali Loss: 0.7154805 Test Loss: 1.7500914
Validation loss decreased (0.739535 --> 0.715481).  Saving model ...
Updating learning rate to 8.388608000000004e-05
Epoch: 11 cost time: 0.5089154243469238
Epoch: 11, Steps: 81 | Train Loss: 0.6517273 Vali Loss: 0.7369712 Test Loss: 1.8372974
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.710886400000004e-05
Epoch: 12 cost time: 0.4844212532043457
Epoch: 12, Steps: 81 | Train Loss: 0.6430595 Vali Loss: 0.7122933 Test Loss: 1.7464951
Validation loss decreased (0.715481 --> 0.712293).  Saving model ...
Updating learning rate to 5.368709120000003e-05
Epoch: 13 cost time: 0.4854145050048828
Epoch: 13, Steps: 81 | Train Loss: 0.6281838 Vali Loss: 0.7011441 Test Loss: 1.7676225
Validation loss decreased (0.712293 --> 0.701144).  Saving model ...
Updating learning rate to 4.294967296000003e-05
Epoch: 14 cost time: 0.4833872318267822
Epoch: 14, Steps: 81 | Train Loss: 0.6171141 Vali Loss: 0.7243398 Test Loss: 1.7912170
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.435973836800002e-05
Epoch: 15 cost time: 0.4894092082977295
Epoch: 15, Steps: 81 | Train Loss: 0.6086193 Vali Loss: 0.6942348 Test Loss: 1.7920532
Validation loss decreased (0.701144 --> 0.694235).  Saving model ...
Updating learning rate to 2.7487790694400016e-05
Epoch: 16 cost time: 0.4898982048034668
Epoch: 16, Steps: 81 | Train Loss: 0.6021188 Vali Loss: 0.6917581 Test Loss: 1.7719181
Validation loss decreased (0.694235 --> 0.691758).  Saving model ...
Updating learning rate to 2.1990232555520015e-05
Epoch: 17 cost time: 0.48737406730651855
Epoch: 17, Steps: 81 | Train Loss: 0.5956777 Vali Loss: 0.6916085 Test Loss: 1.7988657
Validation loss decreased (0.691758 --> 0.691609).  Saving model ...
Updating learning rate to 1.7592186044416015e-05
Epoch: 18 cost time: 0.4923572540283203
Epoch: 18, Steps: 81 | Train Loss: 0.5947307 Vali Loss: 0.7037780 Test Loss: 1.8159211
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.4073748835532813e-05
Epoch: 19 cost time: 0.48438429832458496
Epoch: 19, Steps: 81 | Train Loss: 0.5887247 Vali Loss: 0.6854154 Test Loss: 1.7945542
Validation loss decreased (0.691609 --> 0.685415).  Saving model ...
Updating learning rate to 1.125899906842625e-05
Epoch: 20 cost time: 0.49335408210754395
Epoch: 20, Steps: 81 | Train Loss: 0.5854797 Vali Loss: 0.6864974 Test Loss: 1.7976453
EarlyStopping counter: 1 out of 5
Updating learning rate to 9.007199254741001e-06
>>>>>>>testing : illness_12_12_HDKAN_custom_ftM_bz8_sl12_pl12_lr0.0004_dm256_d15_d25_patl3_dr0.0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 182
test shape: (182, 12, 7) (182, 12, 7)
test shape: (182, 12, 7) (182, 12, 7)
mse:1.7945542335510254, mae:0.8041690587997437
