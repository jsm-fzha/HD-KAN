Args in experiment:
Namespace(random_seed=2025, enable_visual=False, save_model=False, percent=100, patch_len=36, degree1=7, degree2=5, is_training=1, model_id='nasdaq_36_36', model='HDKAN', data='custom', root_path='D:\\work\\datasets\\all_datasets\\short-term', data_path='nasdaq.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=36, label_len=0, pred_len=36, use_revin=1, enc_in=12, dec_in=7, c_out=7, d_model=128, dropout=0.0, alpha=0.35, embed='timeF', num_workers=0, itr=1, train_epochs=20, batch_size=16, patience=5, learning_rate=2.5e-05, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', inverse=False)
Use GPU: cuda:0
>>>>>>>start training : nasdaq_36_36_HDKAN_custom_ftM_bz16_sl36_pl36_lr2.5e-05_dm128_d17_d25_patl36_dr0.0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 2668
val 358
test 747
	iters: 100, epoch: 1 | loss: 0.5942726
	speed: 0.0192s/iter; left time: 61.8478s
Epoch: 1 cost time: 1.6370863914489746
Epoch: 1, Steps: 166 | Train Loss: 0.5098180 Vali Loss: 0.5452431 Test Loss: 0.2368844
Validation loss decreased (inf --> 0.545243).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 2 | loss: 0.5791948
	speed: 0.0124s/iter; left time: 37.8474s
Epoch: 2 cost time: 1.0754115581512451
Epoch: 2, Steps: 166 | Train Loss: 0.4925199 Vali Loss: 0.4721065 Test Loss: 0.1798926
Validation loss decreased (0.545243 --> 0.472106).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 3 | loss: 0.3656349
	speed: 0.0197s/iter; left time: 57.0281s
Epoch: 3 cost time: 2.537689685821533
Epoch: 3, Steps: 166 | Train Loss: 0.4587100 Vali Loss: 0.4435518 Test Loss: 0.1605641
Validation loss decreased (0.472106 --> 0.443552).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4596754
	speed: 0.0344s/iter; left time: 93.7706s
Epoch: 4 cost time: 2.9487037658691406
Epoch: 4, Steps: 166 | Train Loss: 0.4502834 Vali Loss: 0.4350236 Test Loss: 0.1557185
Validation loss decreased (0.443552 --> 0.435024).  Saving model ...
Updating learning rate to 2e-05
	iters: 100, epoch: 5 | loss: 0.4131015
	speed: 0.0344s/iter; left time: 87.9117s
Epoch: 5 cost time: 2.923792839050293
Epoch: 5, Steps: 166 | Train Loss: 0.4465478 Vali Loss: 0.4307991 Test Loss: 0.1549615
Validation loss decreased (0.435024 --> 0.430799).  Saving model ...
Updating learning rate to 1.6000000000000003e-05
	iters: 100, epoch: 6 | loss: 0.3876770
	speed: 0.0344s/iter; left time: 82.1806s
Epoch: 6 cost time: 2.936741352081299
Epoch: 6, Steps: 166 | Train Loss: 0.4447021 Vali Loss: 0.4317580 Test Loss: 0.1532539
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.2800000000000003e-05
	iters: 100, epoch: 7 | loss: 0.3568121
	speed: 0.0364s/iter; left time: 80.9797s
Epoch: 7 cost time: 3.1974759101867676
Epoch: 7, Steps: 166 | Train Loss: 0.4427411 Vali Loss: 0.4268197 Test Loss: 0.1526398
Validation loss decreased (0.430799 --> 0.426820).  Saving model ...
Updating learning rate to 1.0240000000000002e-05
	iters: 100, epoch: 8 | loss: 0.4698130
	speed: 0.0357s/iter; left time: 73.4579s
Epoch: 8 cost time: 3.0184829235076904
Epoch: 8, Steps: 166 | Train Loss: 0.4421242 Vali Loss: 0.4282540 Test Loss: 0.1533840
EarlyStopping counter: 1 out of 5
Updating learning rate to 8.192000000000002e-06
	iters: 100, epoch: 9 | loss: 0.4010765
	speed: 0.0357s/iter; left time: 67.5274s
Epoch: 9 cost time: 3.0519356727600098
Epoch: 9, Steps: 166 | Train Loss: 0.4412984 Vali Loss: 0.4255862 Test Loss: 0.1526559
Validation loss decreased (0.426820 --> 0.425586).  Saving model ...
Updating learning rate to 6.553600000000003e-06
	iters: 100, epoch: 10 | loss: 0.3952962
	speed: 0.0321s/iter; left time: 55.4684s
Epoch: 10 cost time: 2.099993944168091
Epoch: 10, Steps: 166 | Train Loss: 0.4413177 Vali Loss: 0.4265397 Test Loss: 0.1526971
EarlyStopping counter: 1 out of 5
Updating learning rate to 5.242880000000002e-06
	iters: 100, epoch: 11 | loss: 0.4045236
	speed: 0.0176s/iter; left time: 27.4689s
Epoch: 11 cost time: 1.5802998542785645
Epoch: 11, Steps: 166 | Train Loss: 0.4406453 Vali Loss: 0.4272565 Test Loss: 0.1530665
EarlyStopping counter: 2 out of 5
Updating learning rate to 4.1943040000000025e-06
	iters: 100, epoch: 12 | loss: 0.3925657
	speed: 0.0189s/iter; left time: 26.3335s
Epoch: 12 cost time: 1.598665714263916
Epoch: 12, Steps: 166 | Train Loss: 0.4402079 Vali Loss: 0.4257809 Test Loss: 0.1530467
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.355443200000002e-06
	iters: 100, epoch: 13 | loss: 0.3983399
	speed: 0.0165s/iter; left time: 20.2300s
Epoch: 13 cost time: 1.1740808486938477
Epoch: 13, Steps: 166 | Train Loss: 0.4386785 Vali Loss: 0.4266266 Test Loss: 0.1530685
EarlyStopping counter: 4 out of 5
Updating learning rate to 2.6843545600000017e-06
	iters: 100, epoch: 14 | loss: 0.4039965
	speed: 0.0121s/iter; left time: 12.9149s
Epoch: 14 cost time: 1.2777376174926758
Epoch: 14, Steps: 166 | Train Loss: 0.4398566 Vali Loss: 0.4255010 Test Loss: 0.1529229
Validation loss decreased (0.425586 --> 0.425501).  Saving model ...
Updating learning rate to 2.1474836480000014e-06
	iters: 100, epoch: 15 | loss: 0.4135946
	speed: 0.0293s/iter; left time: 26.2979s
Epoch: 15 cost time: 3.016489028930664
Epoch: 15, Steps: 166 | Train Loss: 0.4399628 Vali Loss: 0.4252119 Test Loss: 0.1530330
Validation loss decreased (0.425501 --> 0.425212).  Saving model ...
Updating learning rate to 1.717986918400001e-06
	iters: 100, epoch: 16 | loss: 0.3924762
	speed: 0.0351s/iter; left time: 25.6642s
Epoch: 16 cost time: 2.9666748046875
Epoch: 16, Steps: 166 | Train Loss: 0.4395781 Vali Loss: 0.4251562 Test Loss: 0.1529685
Validation loss decreased (0.425212 --> 0.425156).  Saving model ...
Updating learning rate to 1.374389534720001e-06
	iters: 100, epoch: 17 | loss: 0.6098387
	speed: 0.0347s/iter; left time: 19.5860s
Epoch: 17 cost time: 2.9716241359710693
Epoch: 17, Steps: 166 | Train Loss: 0.4393730 Vali Loss: 0.4264345 Test Loss: 0.1529498
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.099511627776001e-06
	iters: 100, epoch: 18 | loss: 0.3679976
	speed: 0.0346s/iter; left time: 13.8213s
Epoch: 18 cost time: 2.9716339111328125
Epoch: 18, Steps: 166 | Train Loss: 0.4392636 Vali Loss: 0.4248700 Test Loss: 0.1529715
Validation loss decreased (0.425156 --> 0.424870).  Saving model ...
Updating learning rate to 8.796093022208008e-07
	iters: 100, epoch: 19 | loss: 0.3982658
	speed: 0.0347s/iter; left time: 8.0827s
Epoch: 19 cost time: 2.9676387310028076
Epoch: 19, Steps: 166 | Train Loss: 0.4389942 Vali Loss: 0.4257670 Test Loss: 0.1529924
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.036874417766406e-07
	iters: 100, epoch: 20 | loss: 0.4056477
	speed: 0.0347s/iter; left time: 2.3242s
Epoch: 20 cost time: 2.9556827545166016
Epoch: 20, Steps: 166 | Train Loss: 0.4388348 Vali Loss: 0.4249451 Test Loss: 0.1530200
EarlyStopping counter: 2 out of 5
Updating learning rate to 5.629499534213126e-07
>>>>>>>testing : nasdaq_36_36_HDKAN_custom_ftM_bz16_sl36_pl36_lr2.5e-05_dm128_d17_d25_patl36_dr0.0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 747
test shape: (747, 36, 12) (747, 36, 12)
test shape: (747, 36, 12) (747, 36, 12)
mse:0.15297150611877441, mae:0.251475989818573
