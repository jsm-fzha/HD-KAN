Args in experiment:
Namespace(random_seed=2025, enable_visual=False, save_model=False, percent=100, patch_len=36, degree1=8, degree2=7, is_training=1, model_id='wiki_36_36', model='HDKAN', data='custom', root_path='D:\\work\\datasets\\all_datasets\\short-term', data_path='wiki_mini.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=36, label_len=0, pred_len=36, use_revin=0, enc_in=99, dec_in=7, c_out=7, d_model=256, dropout=0.0, alpha=0.0, embed='timeF', num_workers=0, itr=1, train_epochs=20, batch_size=8, patience=5, learning_rate=5e-05, des='test', loss='mse', lradj='type1', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', inverse=False)
Use GPU: cuda:0
>>>>>>>start training : wiki_36_36_HDKAN_custom_ftM_bz8_sl36_pl36_lr5e-05_dm256_d18_d27_patl36_dr0.0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 439
val 39
test 111
Epoch: 1 cost time: 1.0221772193908691
Epoch: 1, Steps: 54 | Train Loss: 0.4726016 Vali Loss: 0.6012494 Test Loss: 6.4898825
Validation loss decreased (inf --> 0.601249).  Saving model ...
Updating learning rate to 5e-05
Epoch: 2 cost time: 0.827239990234375
Epoch: 2, Steps: 54 | Train Loss: 0.4107202 Vali Loss: 0.4724997 Test Loss: 6.3826156
Validation loss decreased (0.601249 --> 0.472500).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 3 cost time: 0.7146165370941162
Epoch: 3, Steps: 54 | Train Loss: 0.3873170 Vali Loss: 0.4653019 Test Loss: 6.3711209
Validation loss decreased (0.472500 --> 0.465302).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 4 cost time: 0.506310224533081
Epoch: 4, Steps: 54 | Train Loss: 0.3820306 Vali Loss: 0.4666031 Test Loss: 6.3677425
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
Epoch: 5 cost time: 0.5477221012115479
Epoch: 5, Steps: 54 | Train Loss: 0.3784339 Vali Loss: 0.4590827 Test Loss: 6.3660712
Validation loss decreased (0.465302 --> 0.459083).  Saving model ...
Updating learning rate to 3.125e-06
Epoch: 6 cost time: 0.53122878074646
Epoch: 6, Steps: 54 | Train Loss: 0.3763635 Vali Loss: 0.4615841 Test Loss: 6.3640919
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
Epoch: 7 cost time: 0.4764106273651123
Epoch: 7, Steps: 54 | Train Loss: 0.3752227 Vali Loss: 0.4590504 Test Loss: 6.3639917
Validation loss decreased (0.459083 --> 0.459050).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 8 cost time: 0.5382046699523926
Epoch: 8, Steps: 54 | Train Loss: 0.3749929 Vali Loss: 0.4600511 Test Loss: 6.3635597
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
Epoch: 9 cost time: 0.5168213844299316
Epoch: 9, Steps: 54 | Train Loss: 0.3745796 Vali Loss: 0.4530922 Test Loss: 6.3634877
Validation loss decreased (0.459050 --> 0.453092).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 10 cost time: 0.507307767868042
Epoch: 10, Steps: 54 | Train Loss: 0.3744560 Vali Loss: 0.4601682 Test Loss: 6.3634715
EarlyStopping counter: 1 out of 5
Updating learning rate to 9.765625e-08
Epoch: 11 cost time: 0.49589014053344727
Epoch: 11, Steps: 54 | Train Loss: 0.3742787 Vali Loss: 0.4585548 Test Loss: 6.3634348
EarlyStopping counter: 2 out of 5
Updating learning rate to 4.8828125e-08
Epoch: 12 cost time: 0.4943506717681885
Epoch: 12, Steps: 54 | Train Loss: 0.3742258 Vali Loss: 0.4617969 Test Loss: 6.3634305
EarlyStopping counter: 3 out of 5
Updating learning rate to 2.44140625e-08
Epoch: 13 cost time: 0.5073080062866211
Epoch: 13, Steps: 54 | Train Loss: 0.3740920 Vali Loss: 0.4717415 Test Loss: 6.3634238
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.220703125e-08
Epoch: 14 cost time: 0.488370418548584
Epoch: 14, Steps: 54 | Train Loss: 0.3742220 Vali Loss: 0.4644741 Test Loss: 6.3634229
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : wiki_36_36_HDKAN_custom_ftM_bz8_sl36_pl36_lr5e-05_dm256_d18_d27_patl36_dr0.0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 111
test shape: (111, 36, 99) (111, 36, 99)
test shape: (111, 36, 99) (111, 36, 99)
mse:6.363487720489502, mae:0.4370846152305603
