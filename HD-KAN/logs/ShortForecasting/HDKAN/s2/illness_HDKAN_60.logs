Args in experiment:
Namespace(random_seed=2025, enable_visual=False, save_model=False, percent=100, patch_len=9, degree1=7, degree2=7, is_training=1, model_id='illness_36_60', model='HDKAN', data='custom', root_path='D:\\work\\datasets\\all_datasets\\short-term', data_path='national_illness.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=36, label_len=0, pred_len=60, use_revin=1, enc_in=7, dec_in=7, c_out=7, d_model=128, dropout=0.0, alpha=0.35, embed='timeF', num_workers=0, itr=1, train_epochs=20, batch_size=8, patience=5, learning_rate=0.0003, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', inverse=False)
Use GPU: cuda:0
>>>>>>>start training : illness_36_60_HDKAN_custom_ftM_bz8_sl36_pl60_lr0.0003_dm128_d17_d27_patl9_dr0.0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 581
val 38
test 134
Epoch: 1 cost time: 0.6264171600341797
Epoch: 1, Steps: 72 | Train Loss: 1.7590818 Vali Loss: 1.6184668 Test Loss: 4.2784185
Validation loss decreased (inf --> 1.618467).  Saving model ...
Updating learning rate to 0.0003
Epoch: 2 cost time: 0.44651103019714355
Epoch: 2, Steps: 72 | Train Loss: 1.5379658 Vali Loss: 1.1787246 Test Loss: 2.3861995
Validation loss decreased (1.618467 --> 1.178725).  Saving model ...
Updating learning rate to 0.0003
Epoch: 3 cost time: 0.4455139636993408
Epoch: 3, Steps: 72 | Train Loss: 1.3394423 Vali Loss: 1.0631856 Test Loss: 2.2114275
Validation loss decreased (1.178725 --> 1.063186).  Saving model ...
Updating learning rate to 0.0003
Epoch: 4 cost time: 0.45946788787841797
Epoch: 4, Steps: 72 | Train Loss: 1.2567791 Vali Loss: 1.0363762 Test Loss: 2.1750245
Validation loss decreased (1.063186 --> 1.036376).  Saving model ...
Updating learning rate to 0.00023999999999999998
Epoch: 5 cost time: 0.44805002212524414
Epoch: 5, Steps: 72 | Train Loss: 1.1939604 Vali Loss: 0.9492082 Test Loss: 1.9442694
Validation loss decreased (1.036376 --> 0.949208).  Saving model ...
Updating learning rate to 0.00019200000000000003
Epoch: 6 cost time: 0.4544837474822998
Epoch: 6, Steps: 72 | Train Loss: 1.1419047 Vali Loss: 0.8937869 Test Loss: 1.8385154
Validation loss decreased (0.949208 --> 0.893787).  Saving model ...
Updating learning rate to 0.00015360000000000002
Epoch: 7 cost time: 0.451493501663208
Epoch: 7, Steps: 72 | Train Loss: 1.1170928 Vali Loss: 0.9112308 Test Loss: 1.8216393
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00012288000000000002
Epoch: 8 cost time: 0.44351983070373535
Epoch: 8, Steps: 72 | Train Loss: 1.0881902 Vali Loss: 0.8750669 Test Loss: 1.7527660
Validation loss decreased (0.893787 --> 0.875067).  Saving model ...
Updating learning rate to 9.830400000000001e-05
Epoch: 9 cost time: 0.4614603519439697
Epoch: 9, Steps: 72 | Train Loss: 1.0728958 Vali Loss: 0.9033452 Test Loss: 1.7878757
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.864320000000003e-05
Epoch: 10 cost time: 0.4514937400817871
Epoch: 10, Steps: 72 | Train Loss: 1.0626829 Vali Loss: 0.8754163 Test Loss: 1.7686321
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.291456000000001e-05
Epoch: 11 cost time: 0.4520251750946045
Epoch: 11, Steps: 72 | Train Loss: 1.0479265 Vali Loss: 0.8586877 Test Loss: 1.7364856
Validation loss decreased (0.875067 --> 0.858688).  Saving model ...
Updating learning rate to 5.033164800000002e-05
Epoch: 12 cost time: 0.44651055335998535
Epoch: 12, Steps: 72 | Train Loss: 1.0380854 Vali Loss: 0.8639042 Test Loss: 1.7540230
EarlyStopping counter: 1 out of 5
Updating learning rate to 4.026531840000002e-05
Epoch: 13 cost time: 0.45249056816101074
Epoch: 13, Steps: 72 | Train Loss: 1.0335940 Vali Loss: 0.8722659 Test Loss: 1.7300702
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.221225472000001e-05
Epoch: 14 cost time: 0.45249080657958984
Epoch: 14, Steps: 72 | Train Loss: 1.0271750 Vali Loss: 0.8795213 Test Loss: 1.7126160
EarlyStopping counter: 3 out of 5
Updating learning rate to 2.5769803776000012e-05
Epoch: 15 cost time: 0.4475076198577881
Epoch: 15, Steps: 72 | Train Loss: 1.0280182 Vali Loss: 0.8761148 Test Loss: 1.7306259
EarlyStopping counter: 4 out of 5
Updating learning rate to 2.061584302080001e-05
Epoch: 16 cost time: 0.44651031494140625
Epoch: 16, Steps: 72 | Train Loss: 1.0243088 Vali Loss: 0.8526426 Test Loss: 1.7161300
Validation loss decreased (0.858688 --> 0.852643).  Saving model ...
Updating learning rate to 1.649267441664001e-05
Epoch: 17 cost time: 0.47188520431518555
Epoch: 17, Steps: 72 | Train Loss: 1.0227310 Vali Loss: 0.8622373 Test Loss: 1.7234040
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.319413953331201e-05
Epoch: 18 cost time: 0.4644505977630615
Epoch: 18, Steps: 72 | Train Loss: 1.0220641 Vali Loss: 0.8655400 Test Loss: 1.7100346
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.0555311626649608e-05
Epoch: 19 cost time: 0.4674406051635742
Epoch: 19, Steps: 72 | Train Loss: 1.0203343 Vali Loss: 0.8808669 Test Loss: 1.7096670
EarlyStopping counter: 3 out of 5
Updating learning rate to 8.444249301319686e-06
Epoch: 20 cost time: 0.5033209323883057
Epoch: 20, Steps: 72 | Train Loss: 1.0173887 Vali Loss: 0.8734279 Test Loss: 1.7099402
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.75539944105575e-06
>>>>>>>testing : illness_36_60_HDKAN_custom_ftM_bz8_sl36_pl60_lr0.0003_dm128_d17_d27_patl9_dr0.0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 134
test shape: (134, 60, 7) (134, 60, 7)
test shape: (134, 60, 7) (134, 60, 7)
mse:1.716130018234253, mae:0.8096784949302673
