Args in experiment:
Namespace(random_seed=2025, enable_visual=False, save_model=False, percent=100, patch_len=9, degree1=7, degree2=7, is_training=1, model_id='illness_36_24', model='HDKAN', data='custom', root_path='D:\\work\\datasets\\all_datasets\\short-term', data_path='national_illness.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=36, label_len=0, pred_len=24, use_revin=1, enc_in=7, dec_in=7, c_out=7, d_model=128, dropout=0.0, alpha=0.35, embed='timeF', num_workers=0, itr=1, train_epochs=20, batch_size=8, patience=5, learning_rate=0.0003, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', inverse=False)
Use GPU: cuda:0
>>>>>>>start training : illness_36_24_HDKAN_custom_ftM_bz8_sl36_pl24_lr0.0003_dm128_d17_d27_patl9_dr0.0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 617
val 74
test 170
Epoch: 1 cost time: 0.6318917274475098
Epoch: 1, Steps: 77 | Train Loss: 1.5263161 Vali Loss: 1.5209570 Test Loss: 5.1262002
Validation loss decreased (inf --> 1.520957).  Saving model ...
Updating learning rate to 0.0003
Epoch: 2 cost time: 0.4780001640319824
Epoch: 2, Steps: 77 | Train Loss: 1.1434472 Vali Loss: 0.8900151 Test Loss: 2.5524764
Validation loss decreased (1.520957 --> 0.890015).  Saving model ...
Updating learning rate to 0.0003
Epoch: 3 cost time: 0.46898341178894043
Epoch: 3, Steps: 77 | Train Loss: 0.9097320 Vali Loss: 0.7331924 Test Loss: 2.4694338
Validation loss decreased (0.890015 --> 0.733192).  Saving model ...
Updating learning rate to 0.0003
Epoch: 4 cost time: 0.48438429832458496
Epoch: 4, Steps: 77 | Train Loss: 0.8250155 Vali Loss: 0.6551926 Test Loss: 2.1777968
Validation loss decreased (0.733192 --> 0.655193).  Saving model ...
Updating learning rate to 0.00023999999999999998
Epoch: 5 cost time: 0.47740721702575684
Epoch: 5, Steps: 77 | Train Loss: 0.7666041 Vali Loss: 0.6362437 Test Loss: 1.8497701
Validation loss decreased (0.655193 --> 0.636244).  Saving model ...
Updating learning rate to 0.00019200000000000003
Epoch: 6 cost time: 0.48139381408691406
Epoch: 6, Steps: 77 | Train Loss: 0.7319299 Vali Loss: 0.6218163 Test Loss: 1.7720939
Validation loss decreased (0.636244 --> 0.621816).  Saving model ...
Updating learning rate to 0.00015360000000000002
Epoch: 7 cost time: 0.4953477382659912
Epoch: 7, Steps: 77 | Train Loss: 0.7060517 Vali Loss: 0.6207831 Test Loss: 1.6854390
Validation loss decreased (0.621816 --> 0.620783).  Saving model ...
Updating learning rate to 0.00012288000000000002
Epoch: 8 cost time: 0.47795629501342773
Epoch: 8, Steps: 77 | Train Loss: 0.6890096 Vali Loss: 0.6105081 Test Loss: 1.6567534
Validation loss decreased (0.620783 --> 0.610508).  Saving model ...
Updating learning rate to 9.830400000000001e-05
Epoch: 9 cost time: 0.47441697120666504
Epoch: 9, Steps: 77 | Train Loss: 0.6788056 Vali Loss: 0.6254874 Test Loss: 1.6699946
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.864320000000003e-05
Epoch: 10 cost time: 0.49634432792663574
Epoch: 10, Steps: 77 | Train Loss: 0.6667134 Vali Loss: 0.6122459 Test Loss: 1.6134170
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.291456000000001e-05
Epoch: 11 cost time: 0.486377477645874
Epoch: 11, Steps: 77 | Train Loss: 0.6576541 Vali Loss: 0.6153610 Test Loss: 1.6134108
EarlyStopping counter: 3 out of 5
Updating learning rate to 5.033164800000002e-05
Epoch: 12 cost time: 0.4883708953857422
Epoch: 12, Steps: 77 | Train Loss: 0.6511915 Vali Loss: 0.6033199 Test Loss: 1.6059057
Validation loss decreased (0.610508 --> 0.603320).  Saving model ...
Updating learning rate to 4.026531840000002e-05
Epoch: 13 cost time: 0.4664435386657715
Epoch: 13, Steps: 77 | Train Loss: 0.6467714 Vali Loss: 0.6155016 Test Loss: 1.5977234
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.221225472000001e-05
Epoch: 14 cost time: 0.47197437286376953
Epoch: 14, Steps: 77 | Train Loss: 0.6431948 Vali Loss: 0.6016713 Test Loss: 1.5698416
Validation loss decreased (0.603320 --> 0.601671).  Saving model ...
Updating learning rate to 2.5769803776000012e-05
Epoch: 15 cost time: 0.4983375072479248
Epoch: 15, Steps: 77 | Train Loss: 0.6394900 Vali Loss: 0.6148376 Test Loss: 1.6012655
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.061584302080001e-05
Epoch: 16 cost time: 0.47740745544433594
Epoch: 16, Steps: 77 | Train Loss: 0.6355927 Vali Loss: 0.6095681 Test Loss: 1.5720197
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.649267441664001e-05
Epoch: 17 cost time: 0.479400634765625
Epoch: 17, Steps: 77 | Train Loss: 0.6357762 Vali Loss: 0.6157050 Test Loss: 1.5901406
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.319413953331201e-05
Epoch: 18 cost time: 0.49335455894470215
Epoch: 18, Steps: 77 | Train Loss: 0.6337530 Vali Loss: 0.6113446 Test Loss: 1.5786600
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.0555311626649608e-05
Epoch: 19 cost time: 0.4999349117279053
Epoch: 19, Steps: 77 | Train Loss: 0.6336373 Vali Loss: 0.6026420 Test Loss: 1.5752661
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : illness_36_24_HDKAN_custom_ftM_bz8_sl36_pl24_lr0.0003_dm128_d17_d27_patl9_dr0.0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 170
test shape: (170, 24, 7) (170, 24, 7)
test shape: (170, 24, 7) (170, 24, 7)
mse:1.5698416233062744, mae:0.7611455917358398
