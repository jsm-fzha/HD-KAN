Args in experiment:
Namespace(random_seed=2025, enable_visual=False, save_model=False, percent=100, patch_len=36, degree1=7, degree2=5, is_training=1, model_id='nasdaq_36_60', model='HDKAN', data='custom', root_path='D:\\work\\datasets\\all_datasets\\short-term', data_path='nasdaq.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=36, label_len=0, pred_len=60, use_revin=1, enc_in=12, dec_in=7, c_out=7, d_model=128, dropout=0.0, alpha=0.35, embed='timeF', num_workers=0, itr=1, train_epochs=20, batch_size=16, patience=5, learning_rate=2.5e-05, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', inverse=False)
Use GPU: cuda:0
>>>>>>>start training : nasdaq_36_60_HDKAN_custom_ftM_bz16_sl36_pl60_lr2.5e-05_dm128_d17_d25_patl36_dr0.0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 2644
val 334
test 723
	iters: 100, epoch: 1 | loss: 0.6124075
	speed: 0.0255s/iter; left time: 81.6903s
Epoch: 1 cost time: 2.475741147994995
Epoch: 1, Steps: 165 | Train Loss: 0.6376622 Vali Loss: 0.7192606 Test Loss: 0.3276779
Validation loss decreased (inf --> 0.719261).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 2 | loss: 0.5934895
	speed: 0.0205s/iter; left time: 62.0940s
Epoch: 2 cost time: 1.8528997898101807
Epoch: 2, Steps: 165 | Train Loss: 0.6295811 Vali Loss: 0.6839862 Test Loss: 0.2975256
Validation loss decreased (0.719261 --> 0.683986).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 3 | loss: 0.5891333
	speed: 0.0212s/iter; left time: 60.8949s
Epoch: 3 cost time: 1.8170523643493652
Epoch: 3, Steps: 165 | Train Loss: 0.6037244 Vali Loss: 0.6207603 Test Loss: 0.2545216
Validation loss decreased (0.683986 --> 0.620760).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5186074
	speed: 0.0207s/iter; left time: 56.0261s
Epoch: 4 cost time: 1.5262517929077148
Epoch: 4, Steps: 165 | Train Loss: 0.5917194 Vali Loss: 0.6022316 Test Loss: 0.2394747
Validation loss decreased (0.620760 --> 0.602232).  Saving model ...
Updating learning rate to 2e-05
	iters: 100, epoch: 5 | loss: 0.5841591
	speed: 0.0131s/iter; left time: 33.3455s
Epoch: 5 cost time: 1.3132946491241455
Epoch: 5, Steps: 165 | Train Loss: 0.5858348 Vali Loss: 0.5982243 Test Loss: 0.2372601
Validation loss decreased (0.602232 --> 0.598224).  Saving model ...
Updating learning rate to 1.6000000000000003e-05
	iters: 100, epoch: 6 | loss: 0.5543933
	speed: 0.0203s/iter; left time: 48.2954s
Epoch: 6 cost time: 1.7580976486206055
Epoch: 6, Steps: 165 | Train Loss: 0.5828993 Vali Loss: 0.5893878 Test Loss: 0.2347247
Validation loss decreased (0.598224 --> 0.589388).  Saving model ...
Updating learning rate to 1.2800000000000003e-05
	iters: 100, epoch: 7 | loss: 0.4892056
	speed: 0.0214s/iter; left time: 47.3244s
Epoch: 7 cost time: 1.8717563152313232
Epoch: 7, Steps: 165 | Train Loss: 0.5809998 Vali Loss: 0.5891512 Test Loss: 0.2361146
Validation loss decreased (0.589388 --> 0.589151).  Saving model ...
Updating learning rate to 1.0240000000000002e-05
	iters: 100, epoch: 8 | loss: 0.6643724
	speed: 0.0163s/iter; left time: 33.4003s
Epoch: 8 cost time: 1.3444302082061768
Epoch: 8, Steps: 165 | Train Loss: 0.5793984 Vali Loss: 0.5843739 Test Loss: 0.2354765
Validation loss decreased (0.589151 --> 0.584374).  Saving model ...
Updating learning rate to 8.192000000000002e-06
	iters: 100, epoch: 9 | loss: 0.5696183
	speed: 0.0140s/iter; left time: 26.4152s
Epoch: 9 cost time: 1.1760766506195068
Epoch: 9, Steps: 165 | Train Loss: 0.5783132 Vali Loss: 0.5825765 Test Loss: 0.2354503
Validation loss decreased (0.584374 --> 0.582576).  Saving model ...
Updating learning rate to 6.553600000000003e-06
	iters: 100, epoch: 10 | loss: 0.4921208
	speed: 0.0131s/iter; left time: 22.4391s
Epoch: 10 cost time: 1.1088361740112305
Epoch: 10, Steps: 165 | Train Loss: 0.5773978 Vali Loss: 0.5829070 Test Loss: 0.2352854
EarlyStopping counter: 1 out of 5
Updating learning rate to 5.242880000000002e-06
	iters: 100, epoch: 11 | loss: 0.5696326
	speed: 0.0185s/iter; left time: 28.7209s
Epoch: 11 cost time: 1.7984082698822021
Epoch: 11, Steps: 165 | Train Loss: 0.5768442 Vali Loss: 0.5820403 Test Loss: 0.2357682
Validation loss decreased (0.582576 --> 0.582040).  Saving model ...
Updating learning rate to 4.1943040000000025e-06
	iters: 100, epoch: 12 | loss: 0.5883591
	speed: 0.0139s/iter; left time: 19.2794s
Epoch: 12 cost time: 1.1827013492584229
Epoch: 12, Steps: 165 | Train Loss: 0.5766664 Vali Loss: 0.5795527 Test Loss: 0.2360999
Validation loss decreased (0.582040 --> 0.579553).  Saving model ...
Updating learning rate to 3.355443200000002e-06
	iters: 100, epoch: 13 | loss: 0.6426528
	speed: 0.0145s/iter; left time: 17.6943s
Epoch: 13 cost time: 1.2827210426330566
Epoch: 13, Steps: 165 | Train Loss: 0.5763006 Vali Loss: 0.5805171 Test Loss: 0.2363087
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.6843545600000017e-06
	iters: 100, epoch: 14 | loss: 0.4952417
	speed: 0.0138s/iter; left time: 14.5688s
Epoch: 14 cost time: 1.1846914291381836
Epoch: 14, Steps: 165 | Train Loss: 0.5760654 Vali Loss: 0.5811685 Test Loss: 0.2363535
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.1474836480000014e-06
	iters: 100, epoch: 15 | loss: 0.5426311
	speed: 0.0177s/iter; left time: 15.8000s
Epoch: 15 cost time: 1.7058663368225098
Epoch: 15, Steps: 165 | Train Loss: 0.5756431 Vali Loss: 0.5813313 Test Loss: 0.2366158
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.717986918400001e-06
	iters: 100, epoch: 16 | loss: 0.4475066
	speed: 0.0141s/iter; left time: 10.2356s
Epoch: 16 cost time: 1.2704684734344482
Epoch: 16, Steps: 165 | Train Loss: 0.5751371 Vali Loss: 0.5788832 Test Loss: 0.2367071
Validation loss decreased (0.579553 --> 0.578883).  Saving model ...
Updating learning rate to 1.374389534720001e-06
	iters: 100, epoch: 17 | loss: 0.6703199
	speed: 0.0189s/iter; left time: 10.6299s
Epoch: 17 cost time: 1.5597953796386719
Epoch: 17, Steps: 165 | Train Loss: 0.5754821 Vali Loss: 0.5811967 Test Loss: 0.2367436
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.099511627776001e-06
	iters: 100, epoch: 18 | loss: 0.5850314
	speed: 0.0129s/iter; left time: 5.0897s
Epoch: 18 cost time: 1.0719833374023438
Epoch: 18, Steps: 165 | Train Loss: 0.5754128 Vali Loss: 0.5787398 Test Loss: 0.2368093
Validation loss decreased (0.578883 --> 0.578740).  Saving model ...
Updating learning rate to 8.796093022208008e-07
	iters: 100, epoch: 19 | loss: 0.5237843
	speed: 0.0128s/iter; left time: 2.9545s
Epoch: 19 cost time: 1.120511770248413
Epoch: 19, Steps: 165 | Train Loss: 0.5748866 Vali Loss: 0.5795846 Test Loss: 0.2368491
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.036874417766406e-07
	iters: 100, epoch: 20 | loss: 0.5474520
	speed: 0.0120s/iter; left time: 0.7900s
Epoch: 20 cost time: 1.0709662437438965
Epoch: 20, Steps: 165 | Train Loss: 0.5750989 Vali Loss: 0.5779197 Test Loss: 0.2368808
Validation loss decreased (0.578740 --> 0.577920).  Saving model ...
Updating learning rate to 5.629499534213126e-07
>>>>>>>testing : nasdaq_36_60_HDKAN_custom_ftM_bz16_sl36_pl60_lr2.5e-05_dm128_d17_d25_patl36_dr0.0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 723
test shape: (723, 60, 12) (723, 60, 12)
test shape: (723, 60, 12) (723, 60, 12)
mse:0.2368808388710022, mae:0.3225928544998169
