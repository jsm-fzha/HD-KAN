Args in experiment:
Namespace(random_seed=2025, enable_visual=False, save_model=False, percent=100, patch_len=3, degree1=4, degree2=5, is_training=1, model_id='nasdaq_12_3', model='HDKAN', data='custom', root_path='D:\\work\\datasets\\all_datasets\\short-term', data_path='nasdaq.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=12, label_len=0, pred_len=3, use_revin=1, enc_in=12, dec_in=7, c_out=7, d_model=128, dropout=0.1, alpha=0.35, embed='timeF', num_workers=0, itr=1, train_epochs=20, batch_size=16, patience=5, learning_rate=0.0001, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', inverse=False)
Use GPU: cuda:0
>>>>>>>start training : nasdaq_12_3_HDKAN_custom_ftM_bz16_sl12_pl3_lr0.0001_dm128_d14_d25_patl3_dr0.1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 2725
val 391
test 780
	iters: 100, epoch: 1 | loss: 0.1786861
	speed: 0.0143s/iter; left time: 47.2449s
Epoch: 1 cost time: 1.2448475360870361
Epoch: 1, Steps: 170 | Train Loss: 0.1583613 Vali Loss: 0.1499857 Test Loss: 0.0599115
Validation loss decreased (inf --> 0.149986).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1122932
	speed: 0.0121s/iter; left time: 37.8705s
Epoch: 2 cost time: 1.0490672588348389
Epoch: 2, Steps: 170 | Train Loss: 0.1249621 Vali Loss: 0.1079814 Test Loss: 0.0358380
Validation loss decreased (0.149986 --> 0.107981).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.1513955
	speed: 0.0120s/iter; left time: 35.5788s
Epoch: 3 cost time: 1.0480940341949463
Epoch: 3, Steps: 170 | Train Loss: 0.1141298 Vali Loss: 0.1062073 Test Loss: 0.0348047
Validation loss decreased (0.107981 --> 0.106207).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.0901158
	speed: 0.0120s/iter; left time: 33.4919s
Epoch: 4 cost time: 1.046509027481079
Epoch: 4, Steps: 170 | Train Loss: 0.1131111 Vali Loss: 0.1059995 Test Loss: 0.0344658
Validation loss decreased (0.106207 --> 0.106000).  Saving model ...
Updating learning rate to 8e-05
	iters: 100, epoch: 5 | loss: 0.1433359
	speed: 0.0120s/iter; left time: 31.4660s
Epoch: 5 cost time: 1.0494990348815918
Epoch: 5, Steps: 170 | Train Loss: 0.1126579 Vali Loss: 0.1059561 Test Loss: 0.0344537
Validation loss decreased (0.106000 --> 0.105956).  Saving model ...
Updating learning rate to 6.400000000000001e-05
	iters: 100, epoch: 6 | loss: 0.0980291
	speed: 0.0122s/iter; left time: 29.9249s
Epoch: 6 cost time: 1.0823888778686523
Epoch: 6, Steps: 170 | Train Loss: 0.1121873 Vali Loss: 0.1056028 Test Loss: 0.0343914
Validation loss decreased (0.105956 --> 0.105603).  Saving model ...
Updating learning rate to 5.120000000000001e-05
	iters: 100, epoch: 7 | loss: 0.1113896
	speed: 0.0122s/iter; left time: 27.8843s
Epoch: 7 cost time: 1.0749499797821045
Epoch: 7, Steps: 170 | Train Loss: 0.1117873 Vali Loss: 0.1059857 Test Loss: 0.0344163
EarlyStopping counter: 1 out of 5
Updating learning rate to 4.096000000000001e-05
	iters: 100, epoch: 8 | loss: 0.1145580
	speed: 0.0121s/iter; left time: 25.4792s
Epoch: 8 cost time: 1.0564756393432617
Epoch: 8, Steps: 170 | Train Loss: 0.1117198 Vali Loss: 0.1054385 Test Loss: 0.0344245
Validation loss decreased (0.105603 --> 0.105438).  Saving model ...
Updating learning rate to 3.276800000000001e-05
	iters: 100, epoch: 9 | loss: 0.0898239
	speed: 0.0123s/iter; left time: 23.7949s
Epoch: 9 cost time: 1.0719943046569824
Epoch: 9, Steps: 170 | Train Loss: 0.1116709 Vali Loss: 0.1059303 Test Loss: 0.0343861
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.621440000000001e-05
	iters: 100, epoch: 10 | loss: 0.1225837
	speed: 0.0121s/iter; left time: 21.3679s
Epoch: 10 cost time: 1.0644488334655762
Epoch: 10, Steps: 170 | Train Loss: 0.1113891 Vali Loss: 0.1058410 Test Loss: 0.0343948
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.097152000000001e-05
	iters: 100, epoch: 11 | loss: 0.1614147
	speed: 0.0122s/iter; left time: 19.5630s
Epoch: 11 cost time: 1.0714259147644043
Epoch: 11, Steps: 170 | Train Loss: 0.1112664 Vali Loss: 0.1055852 Test Loss: 0.0343977
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.677721600000001e-05
	iters: 100, epoch: 12 | loss: 0.1406330
	speed: 0.0122s/iter; left time: 17.5225s
Epoch: 12 cost time: 1.0889427661895752
Epoch: 12, Steps: 170 | Train Loss: 0.1113407 Vali Loss: 0.1061247 Test Loss: 0.0344543
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.3421772800000007e-05
	iters: 100, epoch: 13 | loss: 0.1278681
	speed: 0.0124s/iter; left time: 15.6221s
Epoch: 13 cost time: 1.0843827724456787
Epoch: 13, Steps: 170 | Train Loss: 0.1111231 Vali Loss: 0.1054875 Test Loss: 0.0344514
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : nasdaq_12_3_HDKAN_custom_ftM_bz16_sl12_pl3_lr0.0001_dm128_d14_d25_patl3_dr0.1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 780
test shape: (780, 3, 12) (780, 3, 12)
test shape: (780, 3, 12) (780, 3, 12)
mse:0.03442446142435074, mae:0.09035806357860565
