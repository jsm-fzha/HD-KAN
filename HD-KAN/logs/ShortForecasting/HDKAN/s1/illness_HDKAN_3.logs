Args in experiment:
Namespace(random_seed=2025, enable_visual=False, save_model=False, percent=100, patch_len=3, degree1=5, degree2=5, is_training=1, model_id='illness_12_3', model='HDKAN', data='custom', root_path='D:\\work\\datasets\\all_datasets\\short-term', data_path='national_illness.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=12, label_len=0, pred_len=3, use_revin=1, enc_in=7, dec_in=7, c_out=7, d_model=256, dropout=0.0, alpha=0.35, embed='timeF', num_workers=0, itr=1, train_epochs=20, batch_size=8, patience=5, learning_rate=0.0004, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', inverse=False)
Use GPU: cuda:0
>>>>>>>start training : illness_12_3_HDKAN_custom_ftM_bz8_sl12_pl3_lr0.0004_dm256_d15_d25_patl3_dr0.0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 662
val 95
test 191
Epoch: 1 cost time: 0.6795234680175781
Epoch: 1, Steps: 82 | Train Loss: 0.6091753 Vali Loss: 0.5698687 Test Loss: 1.5476632
Validation loss decreased (inf --> 0.569869).  Saving model ...
Updating learning rate to 0.0004
Epoch: 2 cost time: 0.49176812171936035
Epoch: 2, Steps: 82 | Train Loss: 0.3538439 Vali Loss: 0.2942089 Test Loss: 0.6704351
Validation loss decreased (0.569869 --> 0.294209).  Saving model ...
Updating learning rate to 0.0004
Epoch: 3 cost time: 0.4909093379974365
Epoch: 3, Steps: 82 | Train Loss: 0.2800567 Vali Loss: 0.2891310 Test Loss: 0.6427990
Validation loss decreased (0.294209 --> 0.289131).  Saving model ...
Updating learning rate to 0.0004
Epoch: 4 cost time: 0.5023243427276611
Epoch: 4, Steps: 82 | Train Loss: 0.2626398 Vali Loss: 0.2713690 Test Loss: 0.6556206
Validation loss decreased (0.289131 --> 0.271369).  Saving model ...
Updating learning rate to 0.00032
Epoch: 5 cost time: 0.5056498050689697
Epoch: 5, Steps: 82 | Train Loss: 0.2546879 Vali Loss: 0.2433966 Test Loss: 0.5496381
Validation loss decreased (0.271369 --> 0.243397).  Saving model ...
Updating learning rate to 0.00025600000000000004
Epoch: 6 cost time: 0.5053143501281738
Epoch: 6, Steps: 82 | Train Loss: 0.2388050 Vali Loss: 0.2376213 Test Loss: 0.5010335
Validation loss decreased (0.243397 --> 0.237621).  Saving model ...
Updating learning rate to 0.00020480000000000004
Epoch: 7 cost time: 0.5152812004089355
Epoch: 7, Steps: 82 | Train Loss: 0.2328627 Vali Loss: 0.2358509 Test Loss: 0.4767286
Validation loss decreased (0.237621 --> 0.235851).  Saving model ...
Updating learning rate to 0.00016384000000000003
Epoch: 8 cost time: 0.5198037624359131
Epoch: 8, Steps: 82 | Train Loss: 0.2270425 Vali Loss: 0.2282474 Test Loss: 0.4610325
Validation loss decreased (0.235851 --> 0.228247).  Saving model ...
Updating learning rate to 0.00013107200000000004
Epoch: 9 cost time: 0.512291669845581
Epoch: 9, Steps: 82 | Train Loss: 0.2172468 Vali Loss: 0.2298242 Test Loss: 0.4927977
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00010485760000000004
Epoch: 10 cost time: 0.5172748565673828
Epoch: 10, Steps: 82 | Train Loss: 0.2137811 Vali Loss: 0.2230440 Test Loss: 0.4188474
Validation loss decreased (0.228247 --> 0.223044).  Saving model ...
Updating learning rate to 8.388608000000004e-05
Epoch: 11 cost time: 0.5083050727844238
Epoch: 11, Steps: 82 | Train Loss: 0.2059428 Vali Loss: 0.2222822 Test Loss: 0.4575410
Validation loss decreased (0.223044 --> 0.222282).  Saving model ...
Updating learning rate to 6.710886400000004e-05
Epoch: 12 cost time: 0.5013277530670166
Epoch: 12, Steps: 82 | Train Loss: 0.2012420 Vali Loss: 0.2202019 Test Loss: 0.4233124
Validation loss decreased (0.222282 --> 0.220202).  Saving model ...
Updating learning rate to 5.368709120000003e-05
Epoch: 13 cost time: 0.5098285675048828
Epoch: 13, Steps: 82 | Train Loss: 0.1950132 Vali Loss: 0.2200470 Test Loss: 0.4117229
Validation loss decreased (0.220202 --> 0.220047).  Saving model ...
Updating learning rate to 4.294967296000003e-05
Epoch: 14 cost time: 0.5302309989929199
Epoch: 14, Steps: 82 | Train Loss: 0.1865782 Vali Loss: 0.2227956 Test Loss: 0.4196886
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.435973836800002e-05
Epoch: 15 cost time: 0.5018792152404785
Epoch: 15, Steps: 82 | Train Loss: 0.1877809 Vali Loss: 0.2168434 Test Loss: 0.4161049
Validation loss decreased (0.220047 --> 0.216843).  Saving model ...
Updating learning rate to 2.7487790694400016e-05
Epoch: 16 cost time: 0.5063109397888184
Epoch: 16, Steps: 82 | Train Loss: 0.1851687 Vali Loss: 0.2198947 Test Loss: 0.4170016
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.1990232555520015e-05
Epoch: 17 cost time: 0.5102977752685547
Epoch: 17, Steps: 82 | Train Loss: 0.1832675 Vali Loss: 0.2134825 Test Loss: 0.4163536
Validation loss decreased (0.216843 --> 0.213482).  Saving model ...
Updating learning rate to 1.7592186044416015e-05
Epoch: 18 cost time: 0.5033209323883057
Epoch: 18, Steps: 82 | Train Loss: 0.1796982 Vali Loss: 0.2178336 Test Loss: 0.4169071
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.4073748835532813e-05
Epoch: 19 cost time: 0.5112943649291992
Epoch: 19, Steps: 82 | Train Loss: 0.1799167 Vali Loss: 0.2144315 Test Loss: 0.4156192
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.125899906842625e-05
Epoch: 20 cost time: 0.4973409175872803
Epoch: 20, Steps: 82 | Train Loss: 0.1792244 Vali Loss: 0.2181548 Test Loss: 0.4149788
EarlyStopping counter: 3 out of 5
Updating learning rate to 9.007199254741001e-06
>>>>>>>testing : illness_12_3_HDKAN_custom_ftM_bz8_sl12_pl3_lr0.0004_dm256_d15_d25_patl3_dr0.0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 191
test shape: (191, 3, 7) (191, 3, 7)
test shape: (191, 3, 7) (191, 3, 7)
mse:0.4163535535335541, mae:0.335710734128952
